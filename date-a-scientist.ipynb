{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
      "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
      "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
      "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
      "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
      "      dtype='object')\n",
      "   age body_type    drinks      drugs ethnicity  height             job  \\\n",
      "0   22      plus  moderate      never     asian    75.0  Transportation   \n",
      "1   35   average     heavy  sometimes     white    70.0         Service   \n",
      "2   38      slim  moderate    unknown   unknown    68.0           Other   \n",
      "3   23      slim  moderate    unknown     white    71.0         Student   \n",
      "4   29       fit  moderate      never     asian    66.0        Creative   \n",
      "\n",
      "     location orientation     religion  ... presence has_kids wants_kids  \\\n",
      "0  california    straight  agnosticism  ...   active       no      maybe   \n",
      "1  california    straight  agnosticism  ...   active       no      maybe   \n",
      "2  california    straight      unknown  ...   active  unknown    unknown   \n",
      "3  california    straight      unknown  ...   active  unknown         no   \n",
      "4  california    straight      unknown  ...   active  unknown    unknown   \n",
      "\n",
      "  likes_dogs has_dogs likes_cats has_cats religion_dedication sign_importance  \\\n",
      "0        yes  unknown        yes  unknown      very dedicated         unknown   \n",
      "1        yes  unknown        yes  unknown           dedicated         unknown   \n",
      "2    unknown  unknown    unknown      yes             unknown   not important   \n",
      "3    unknown  unknown        yes  unknown             unknown         unknown   \n",
      "4        yes  unknown        yes  unknown             unknown         unknown   \n",
      "\n",
      "  languages_count  \n",
      "0               1  \n",
      "1               3  \n",
      "2               2  \n",
      "3               2  \n",
      "4               1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59871 entries, 0 to 59945\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   age                  59871 non-null  int64  \n",
      " 1   body_type            59871 non-null  object \n",
      " 2   drinks               59871 non-null  object \n",
      " 3   drugs                59871 non-null  object \n",
      " 4   ethnicity            59871 non-null  object \n",
      " 5   height               59871 non-null  float64\n",
      " 6   job                  59871 non-null  object \n",
      " 7   location             59871 non-null  object \n",
      " 8   orientation          59871 non-null  object \n",
      " 9   religion             59871 non-null  object \n",
      " 10  sex                  59871 non-null  object \n",
      " 11  sign                 59871 non-null  object \n",
      " 12  smokes               59871 non-null  object \n",
      " 13  status               59871 non-null  object \n",
      " 14  diet_type            59871 non-null  object \n",
      " 15  diet_strictness      59871 non-null  object \n",
      " 16  education_status     59871 non-null  object \n",
      " 17  education_level      59871 non-null  object \n",
      " 18  presence             59871 non-null  object \n",
      " 19  has_kids             59871 non-null  object \n",
      " 20  wants_kids           59871 non-null  object \n",
      " 21  likes_dogs           59871 non-null  object \n",
      " 22  has_dogs             59871 non-null  object \n",
      " 23  likes_cats           59871 non-null  object \n",
      " 24  has_cats             59871 non-null  object \n",
      " 25  religion_dedication  59871 non-null  object \n",
      " 26  sign_importance      59871 non-null  object \n",
      " 27  languages_count      59871 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(25)\n",
      "memory usage: 13.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('profiles.csv')\n",
    "\n",
    "#EDA\n",
    "\n",
    "#print(data.head())\n",
    "#print(data.describe())\n",
    "#print(data.info())\n",
    "#print(data.shape)\n",
    "#print(data.duplicated())\n",
    "#data.isnull().mean().sort_values(ascending=False)  # for percentage\n",
    "#data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#fill null essays with empty string\n",
    "essay_cols = [col for col in data.columns if 'essay' in col]\n",
    "data[essay_cols] = data[essay_cols].fillna('')\n",
    "\n",
    "#drop 3 records without height (was thinking about filling those values with the mean, but since there are only 3 rows, decided to drop them)\n",
    "data = data.dropna(subset=['height'])\n",
    "\n",
    "#fill categorical columns with unkown\n",
    "cat_cols = data.columns\n",
    "print(cat_cols)\n",
    "data[cat_cols] = data[cat_cols].fillna('unknown')\n",
    "\n",
    "#print(data.isnull().sum().sort_values(ascending=False))\n",
    "#print(data.head())\n",
    "\n",
    "#group body types - Group body types into slim, average, fit, plus or unknown\n",
    "def group_body_types(bt):\n",
    "    if bt in ['thin', 'skinny']:\n",
    "        return 'slim'\n",
    "    elif bt == 'average':\n",
    "        return 'average'\n",
    "    elif bt in ['athletic', 'fit', 'jacked']: \n",
    "        return 'fit'\n",
    "    elif bt in ['a little extra', 'curvy', 'full figured', 'overweight']: \n",
    "        return 'plus'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data.body_type = data.body_type.apply(group_body_types)\n",
    "\n",
    "#Diet - for diet there are 2 pieces of info in this column, so I will divide into diet type and diet strictness\n",
    "def fill_diet_type(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1:\n",
    "        return parts[0]\n",
    "    else:\n",
    "        return parts[1]\n",
    "    \n",
    "data['diet_type'] = data['diet'].apply(fill_diet_type)\n",
    "\n",
    "def fill_diet_strictness(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1 and parts[0] == 'unknown':\n",
    "        return 'unknown'\n",
    "    elif len(parts) == 1: \n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return parts[0]\n",
    "\n",
    "data['diet_strictness'] = data['diet'].apply(fill_diet_strictness)\n",
    "\n",
    "strict_dict = {\n",
    "    'strictly': 'strict',\n",
    "    'mostly': 'flexible',\n",
    "    'neutral': 'standard',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['diet_strictness'] = data['diet_strictness'].map(strict_dict)\n",
    "\n",
    "#drinks - almost perfect, just changed some labels and grouped 2 fields\n",
    "drinks_dict = {\n",
    "    'unknown': 'unknown',\n",
    "    'not at all': 'non-drinker',\n",
    "    'rarely': 'light',\n",
    "    'socially': 'moderate',\n",
    "    'often': 'heavy',\n",
    "    'very often': 'heavy',\n",
    "    'desperately': 'very heavy',    \n",
    "}\n",
    "\n",
    "data.drinks = data.drinks.map(drinks_dict)\n",
    "\n",
    "#drugs - good to go\n",
    "#education - STILL NEEDS TO BE PROPER CLEANED CHECK THE UNIQUE VALUES AND GROUP THEM AFTER FINISHING CLEANING\n",
    "\n",
    "#print(data.education.unique())\n",
    "\n",
    "def split_education(edu): \n",
    "    if edu is None or pd.isna(edu) or edu == 'unknown' or edu == '':\n",
    "        return pd.Series(['unknown', 'unknown'])\n",
    "    parts = edu.split(' ', 2)\n",
    "    if len(parts) == 1:\n",
    "        return pd.Series(['graduated from', parts[0]])\n",
    "    if len(parts) == 2:\n",
    "        return pd.Series(['graduated from', parts[0] + ' ' + parts[1]])\n",
    "    if len(parts) == 3:\n",
    "        status = parts[0] + ' ' + parts[1]\n",
    "        level = parts[2]\n",
    "        return pd.Series([status, level])\n",
    "\n",
    "data[['education_status', 'education_level']] = data['education'].apply(split_education)\n",
    "\n",
    "map_edu = {\n",
    "    'college/university': 'college',\n",
    "    'space camp': 'unknown',\n",
    "    'masters program': 'masters',\n",
    "    'two-year college': 'college',\n",
    "    'unknown': 'unknown',\n",
    "    'high school': 'high school',\n",
    "    'of space camp': 'unknown',\n",
    "    'ph.d program': 'phd',\n",
    "    'law school': 'law school',\n",
    "    'med school': 'med school',\n",
    "    'of college/university': 'college',\n",
    "    'of high school': 'high school',\n",
    "    'of ph.d program': 'phd',\n",
    "    'of two-year college': 'college',\n",
    "    'of med school': 'med school',\n",
    "    'of masters program': 'masters',\n",
    "    'of law school': 'law school'\n",
    "}\n",
    "\n",
    "edu_status_map = {\n",
    "    'working on': 'in progress',\n",
    "    'graduated from': 'finished',\n",
    "    'unknown': 'unknown',\n",
    "    'dropped out': 'dropped out'\n",
    "}\n",
    "\n",
    "data['education_level'] = data['education_level'].map(map_edu)\n",
    "data['education_status'] = data['education_status'].map(edu_status_map)\n",
    "\n",
    "#print(data.education_status.unique())\n",
    "#print(data.education_level.unique())\n",
    "\n",
    "#ethnicity\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "def get_primary_race(race):\n",
    "    if race == '' or race == 'unknown':\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return race.split(',')[0].strip().lower()\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].apply(get_primary_race)\n",
    "\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "#job\n",
    "#print(data.job.unique())\n",
    "\n",
    "career_map = {\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    \n",
    "    'medicine / health': 'Healthcare',\n",
    "    \n",
    "    'education / academia': 'Education',\n",
    "    \n",
    "    'banking / financial / real estate': 'Business',\n",
    "    'sales / marketing / biz dev': 'Business',\n",
    "    'executive / management': 'Business',\n",
    "    \n",
    "    'artistic / musical / writer': 'Creative',\n",
    "    'entertainment / media': 'Creative',\n",
    "    \n",
    "    'hospitality / travel': 'Service',\n",
    "    'clerical / administrative': 'Service',\n",
    "    'construction / craftsmanship': 'Service',\n",
    "    \n",
    "    'political / government': 'Government / Law',\n",
    "    'law / legal services': 'Government / Law',\n",
    "    'military': 'Government / Law',\n",
    "    \n",
    "    'transportation': 'Transportation',\n",
    "    \n",
    "    'student': 'Student',\n",
    "    'unemployed': 'Unemployed',\n",
    "    'retired': 'Retired',\n",
    "    \n",
    "    'rather not say': 'Other',\n",
    "    'other': 'Other',\n",
    "    'unknown': 'Other'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].map(career_map).fillna('Other')\n",
    "\n",
    "#print(data.job.unique())\n",
    "\n",
    "#last_online\n",
    "#print(data.last_online.unique())\n",
    "\n",
    "data['last_online'] = pd.to_datetime(data['last_online'], format='%Y-%m-%d-%H-%M')\n",
    "most_recent_date = data['last_online'].max()\n",
    "data['last_online'] = (most_recent_date - data['last_online']).dt.days\n",
    "\n",
    "def convert_lastonline_to_cat(lo):\n",
    "    if lo <= 7:\n",
    "        return 'active'\n",
    "    elif lo < 14:\n",
    "        return 'semi-active'\n",
    "    else:\n",
    "        return 'not active'\n",
    "\n",
    "data['presence'] = data['last_online'].apply(convert_lastonline_to_cat)\n",
    "\n",
    "#location\n",
    "#print(data.location.unique())\n",
    "\n",
    "def get_main_location(location):\n",
    "    return location.split(',')[1].strip()\n",
    "\n",
    "data['location'] = data['location'].apply(get_main_location)\n",
    "\n",
    "#offspring\n",
    "#print(data.offspring.unique())\n",
    "\n",
    "data['offspring'] = data['offspring'].str.replace(\"doesn&rsquo;t\", \"doesn't\", regex=False)\n",
    "\n",
    "has_kids_conditions = [\n",
    "    data['offspring'].str.contains('has a kid|has kids', case = False),\n",
    "    data['offspring'].str.contains('doesn\\'t have kids', case = False)\n",
    "]\n",
    "\n",
    "has_kids_choices = ['yes', 'no']\n",
    "\n",
    "data['has_kids'] = np.select(has_kids_conditions, has_kids_choices, default = 'unknown')\n",
    "\n",
    "wants_kids_conditions = [\n",
    "    data['offspring'].str.contains('doesn\\'t want', case=False),\n",
    "    data['offspring'].str.contains('might want', case=False),\n",
    "    data['offspring'].str.contains('wants', case=False)\n",
    "]\n",
    " \n",
    "wants_kids_choices = ['no', 'maybe', 'yes']\n",
    "\n",
    "data['wants_kids'] = np.select(wants_kids_conditions, wants_kids_choices, default='unknown')\n",
    "\n",
    "#orientation - already good\n",
    "#print(data.orientation.unique())\n",
    "\n",
    "#pets\n",
    "#print(data.pets.unique())\n",
    "\n",
    "likes_dogs_conditions = [\n",
    "    data['pets'].str.contains('likes dogs', case = False),\n",
    "    data['pets'].str.contains('dislikes dogs', case = False)\n",
    "]\n",
    "\n",
    "likes_dogs_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_dogs'] = np.select(likes_dogs_conditions, likes_dogs_choices, default = 'unknown')\n",
    "\n",
    "has_dogs_conditions = [\n",
    "    data['pets'].str.contains('has dogs', case = False)\n",
    "]\n",
    "\n",
    "has_dogs_choices = ['yes']\n",
    "\n",
    "data['has_dogs'] = np.select(has_dogs_conditions, has_dogs_choices, default = 'unknown')\n",
    "\n",
    "likes_cats_conditions = [\n",
    "    data['pets'].str.contains('likes cats', case = False),\n",
    "    data['pets'].str.contains('dislikes cats', case = False)\n",
    "]\n",
    "\n",
    "likes_cats_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_cats'] = np.select(likes_cats_conditions, likes_cats_choices, default = 'unknown')\n",
    "\n",
    "has_cats_conditions = [\n",
    "    data['pets'].str.contains('has cats', case = False)\n",
    "]\n",
    "\n",
    "has_cats_choices = ['yes']\n",
    "\n",
    "data['has_cats'] = np.select(has_cats_conditions, has_cats_choices, default = 'unknown')\n",
    "\n",
    "# religion\n",
    "#print(data.religion.unique())\n",
    "\n",
    "religion_dedication_condition = [\n",
    "    data['religion'].str.contains('very serious', case = False),\n",
    "    data['religion'].str.contains('not too serious', case = False),\n",
    "    data['religion'].str.contains('somewhat', case = False),\n",
    "    data['religion'].str.contains('laughing', case = False)\n",
    "]\n",
    "\n",
    "religion_dedication_values = ['very dedicated', 'dedicated', 'partially dedicated', 'not dedicated']\n",
    "\n",
    "data['religion_dedication'] = np.select(religion_dedication_condition, religion_dedication_values, default = 'unknown')\n",
    "\n",
    "def set_religion(r):\n",
    "    return r.split(' ', 2)[0]\n",
    "\n",
    "data['religion'] = data.religion.apply(set_religion)\n",
    "\n",
    "#sex - no changes needed\n",
    "#print(data.sex.unique())\n",
    "\n",
    "#sign \n",
    "#print(data.sign.unique())\n",
    "\n",
    "data['sign'] = data['sign'].str.replace('doesn&rsquo;t', 'doesn\\'t', regex=False)\n",
    "data['sign'] = data['sign'].str.replace('it&rsquo;s', 'it\\'s', regex=False)\n",
    "\n",
    "sign_importance_conditions = [\n",
    "    data['sign'].str.contains('doesn\\'t matter', case = False),\n",
    "    data['sign'].str.contains('fun', case = False),\n",
    "    data['sign'].str.contains('it matters', case = False)\n",
    "]\n",
    "\n",
    "sign_importance_options = ['not important', 'fun', 'important']\n",
    "\n",
    "data['sign_importance'] = np.select(sign_importance_conditions, sign_importance_options, default = 'unknown')\n",
    "\n",
    "def set_sign(sign):\n",
    "    return sign.split(' ', 2)[0]\n",
    "\n",
    "data['sign'] = data['sign'].apply(set_sign)\n",
    "\n",
    "#smokes\n",
    "#print(data.smokes.unique())\n",
    "\n",
    "map_smoking = {\n",
    "    'when drinking': 'sometimes',\n",
    "    'trying to quit': 'yes'\n",
    "}\n",
    "\n",
    "data['smokes'] = data['smokes'].replace(map_smoking)\n",
    "\n",
    "#speaks\n",
    "#print(data.speaks.unique())\n",
    "\n",
    "\"\"\"\n",
    "language_counts = {}\n",
    "for record in data.speaks.unique():\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l in language_counts:\n",
    "            language_counts[l] += 1\n",
    "        else:\n",
    "            language_counts[l] = 1\n",
    "\n",
    "sorted_langs = dict(sorted(language_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\"\"\"\n",
    "\n",
    "#decided for now to only store the number of languages spoken\n",
    "\n",
    "def get_language_count(record):\n",
    "    language_count = 0\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l not in ['c++', 'lisp', 'ancient', 'unknown', 'sign']:\n",
    "            language_count += 1\n",
    "    return language_count\n",
    "\n",
    "data['languages_count'] = data['speaks'].apply(get_language_count)\n",
    "#print(data[['languages_count', 'speaks']].head())\n",
    "\n",
    "#Next step: add 1 column for each of the top 10 and add the level for each user\n",
    "\n",
    "#status\n",
    "#print(data.status.unique())\n",
    "\n",
    "status_map = {\n",
    "    'single': 'single',\n",
    "    'available': 'single',\n",
    "    'seeing someone': 'committed',\n",
    "    'married': 'committed',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['status'] = data['status'].map(status_map)\n",
    "#print(data.status.unique())\n",
    "\n",
    "#numerical fields\n",
    "#print(data.describe())\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "data['height'].hist(bins=30)\n",
    "plt.xlabel('Height (inches)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data['age'].hist(bins=30)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "data = data[(data['age'] >= 18) & (data['age'] <= 90)] # reasonable interval for age\n",
    "data = data[(data['height'] >= 54) & (data['height'] <= 84)] # reasonable interval for height\n",
    "\n",
    "data = data.drop(columns=['income']) #around 80% of values are missing, will just drop the column\n",
    "\n",
    "# still need to drop: diet, education, last_online, offspring, pets, speaks -> other columns were created based on this information\n",
    "\n",
    "data = data.drop(columns=['diet', 'education', 'last_online', 'offspring', 'pets', 'speaks'])\n",
    "\n",
    "#now drop columns where unknowns are more than 50%\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "threshold = 0.5\n",
    "high_unknown_cols = []\n",
    "for col in cat_cols:\n",
    "    p = (df[col] == 'unknown').mean()\n",
    "    if p > threshold:\n",
    "        high_unknown_cols.append(col)\n",
    "\n",
    "#print(high_unknown_cols)\n",
    "\n",
    "df = df.drop(columns=high_unknown_cols)\n",
    "\n",
    "not_essay_cols = [col for col in data.columns if 'essay' not in col]\n",
    "print(data[not_essay_cols].head())\n",
    "print(data[not_essay_cols].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535365344467641\n",
      "0.8592066805845512\n",
      "age                              0.083873\n",
      "height                           0.071163\n",
      "languages_count                  0.038180\n",
      "presence_not active              0.020033\n",
      "likes_dogs_yes                   0.018874\n",
      "ethnicity_white                  0.017953\n",
      "likes_cats_yes                   0.017627\n",
      "drugs_unknown                    0.016329\n",
      "drinks_moderate                  0.016021\n",
      "job_Other                        0.015809\n",
      "sex_m                            0.015684\n",
      "religion_dedication_unknown      0.014695\n",
      "body_type_fit                    0.014554\n",
      "has_kids_unknown                 0.014063\n",
      "education_level_masters          0.013776\n",
      "religion_unknown                 0.013747\n",
      "sign_importance_not important    0.013735\n",
      "drugs_sometimes                  0.013718\n",
      "has_dogs_yes                     0.012469\n",
      "sign_importance_unknown          0.012406\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = data[not_essay_cols]\n",
    "#print(df.body_type.value_counts())\n",
    "\n",
    "col_to_predict = 'orientation'\n",
    "\n",
    "#remove rows where the target variable is unknown\n",
    "df = df[df[col_to_predict] != 'unknown']\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col != col_to_predict]\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "#cat_cols = ['sex', 'presence', 'likes_dogs', 'has_kids', 'ethnicity', 'likes_cats']\n",
    "#num_cols = ['age', 'height', 'languages_count']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df_dummies = pd.get_dummies(df[cat_cols], drop_first = True)\n",
    "\n",
    "x = pd.concat([df[num_cols], df_dummies], axis = 1)\n",
    "y = df[col_to_predict]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 24)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver = 'lbfgs', max_iter = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "print(model.score(x_test, y_test))\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "print(rf.score(x_test, y_test))\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=x_train.columns)\n",
    "print(importances.sort_values(ascending=False).head(20))\n",
    "\n",
    "#Check chat gpt code review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
