{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age       body_type               diet    drinks      drugs  \\\n",
      "0   22  a little extra  strictly anything  socially      never   \n",
      "1   35         average       mostly other     often  sometimes   \n",
      "2   38            thin           anything  socially        NaN   \n",
      "3   23            thin         vegetarian  socially        NaN   \n",
      "4   29        athletic                NaN  socially      never   \n",
      "\n",
      "                           education            ethnicity  height  income  \\\n",
      "0      working on college/university         asian, white    75.0      -1   \n",
      "1              working on space camp                white    70.0   80000   \n",
      "2     graduated from masters program                  NaN    68.0      -1   \n",
      "3      working on college/university                white    71.0   20000   \n",
      "4  graduated from college/university  asian, black, other    66.0      -1   \n",
      "\n",
      "                           job  ...                         location  \\\n",
      "0               transportation  ...  south san francisco, california   \n",
      "1         hospitality / travel  ...              oakland, california   \n",
      "2                          NaN  ...        san francisco, california   \n",
      "3                      student  ...             berkeley, california   \n",
      "4  artistic / musical / writer  ...        san francisco, california   \n",
      "\n",
      "                                      offspring orientation  \\\n",
      "0  doesn&rsquo;t have kids, but might want them    straight   \n",
      "1  doesn&rsquo;t have kids, but might want them    straight   \n",
      "2                                           NaN    straight   \n",
      "3                       doesn&rsquo;t want kids    straight   \n",
      "4                                           NaN    straight   \n",
      "\n",
      "                        pets                                  religion sex  \\\n",
      "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
      "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
      "2                   has cats                                       NaN   m   \n",
      "3                 likes cats                                       NaN   m   \n",
      "4  likes dogs and likes cats                                       NaN   m   \n",
      "\n",
      "                                 sign     smokes  \\\n",
      "0                              gemini  sometimes   \n",
      "1                              cancer         no   \n",
      "2  pisces but it doesn&rsquo;t matter         no   \n",
      "3                              pisces         no   \n",
      "4                            aquarius         no   \n",
      "\n",
      "                                              speaks     status  \n",
      "0                                            english     single  \n",
      "1  english (fluently), spanish (poorly), french (...     single  \n",
      "2                               english, french, c++  available  \n",
      "3                           english, german (poorly)     single  \n",
      "4                                            english     single  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "                age        height          income\n",
      "count  59946.000000  59943.000000    59946.000000\n",
      "mean      32.340290     68.295281    20033.222534\n",
      "std        9.452779      3.994803    97346.192104\n",
      "min       18.000000      1.000000       -1.000000\n",
      "25%       26.000000     66.000000       -1.000000\n",
      "50%       30.000000     68.000000       -1.000000\n",
      "75%       37.000000     71.000000       -1.000000\n",
      "max      110.000000     95.000000  1000000.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   ethnicity    54266 non-null  object \n",
      " 7   height       59943 non-null  float64\n",
      " 8   income       59946 non-null  int64  \n",
      " 9   job          51748 non-null  object \n",
      " 10  last_online  59946 non-null  object \n",
      " 11  location     59946 non-null  object \n",
      " 12  offspring    24385 non-null  object \n",
      " 13  orientation  59946 non-null  object \n",
      " 14  pets         40025 non-null  object \n",
      " 15  religion     39720 non-null  object \n",
      " 16  sex          59946 non-null  object \n",
      " 17  sign         48890 non-null  object \n",
      " 18  smokes       54434 non-null  object \n",
      " 19  speaks       59896 non-null  object \n",
      " 20  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n",
      "None\n",
      "(59946, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('profiles.csv')\n",
    "\n",
    "not_essay_cols = [col for col in data.columns if 'essay' not in col]\n",
    "data = data[not_essay_cols]\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "print(data.info())\n",
    "print(data.shape)\n",
    "#print(data.duplicated())\n",
    "#data.isnull().mean().sort_values(ascending=False)  # for percentage\n",
    "#data.isnull().sum().sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
      "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
      "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
      "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
      "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
      "      dtype='object')\n",
      "will drop  ['location', 'status']\n",
      "Dropped columns due to dominance: ['location', 'status']\n",
      "   age body_type drinks    drugs ethnicity  height             job  \\\n",
      "0   22      plus  light       no     asian    75.0  Transportation   \n",
      "1   35   average  heavy      yes     white    70.0         Service   \n",
      "2   38      slim  light  unknown   unknown    68.0           Other   \n",
      "3   23      slim  light  unknown     white    71.0         Student   \n",
      "4   29       fit  light       no     asian    66.0        Creative   \n",
      "\n",
      "  orientation     religion sex      sign smokes   diet_type diet_strictness  \\\n",
      "0    straight  agnosticism   m    gemini    yes    anything          strict   \n",
      "1    straight  agnosticism   m    cancer     no       other        flexible   \n",
      "2    straight      unknown   m    pisces     no    anything        standard   \n",
      "3    straight      unknown   m    pisces     no  vegetarian        standard   \n",
      "4    straight      unknown   m  aquarius     no     unknown         unknown   \n",
      "\n",
      "  education_status education_level presence sign_importance  languages_count  \n",
      "0      in progress         college   active         unknown                1  \n",
      "1      in progress         unknown   active         unknown                3  \n",
      "2         finished         masters   active              no                2  \n",
      "3      in progress         college   active         unknown                2  \n",
      "4         finished         college   active         unknown                1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59871 entries, 0 to 59945\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               59871 non-null  int64  \n",
      " 1   body_type         59871 non-null  object \n",
      " 2   drinks            59871 non-null  object \n",
      " 3   drugs             59871 non-null  object \n",
      " 4   ethnicity         59871 non-null  object \n",
      " 5   height            59871 non-null  float64\n",
      " 6   job               59871 non-null  object \n",
      " 7   orientation       59871 non-null  object \n",
      " 8   religion          59871 non-null  object \n",
      " 9   sex               59871 non-null  object \n",
      " 10  sign              59871 non-null  object \n",
      " 11  smokes            57648 non-null  object \n",
      " 12  diet_type         59871 non-null  object \n",
      " 13  diet_strictness   59871 non-null  object \n",
      " 14  education_status  59871 non-null  object \n",
      " 15  education_level   59871 non-null  object \n",
      " 16  presence          59871 non-null  object \n",
      " 17  sign_importance   59871 non-null  object \n",
      " 18  languages_count   59871 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(16)\n",
      "memory usage: 9.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('profiles.csv')\n",
    "\n",
    "#EDA\n",
    "\n",
    "#fill null essays with empty string\n",
    "essay_cols = [col for col in data.columns if 'essay' in col]\n",
    "data[essay_cols] = data[essay_cols].fillna('')\n",
    "\n",
    "#drop 3 records without height (was thinking about filling those values with the mean, but since there are only 3 rows, decided to drop them)\n",
    "data = data.dropna(subset=['height'])\n",
    "\n",
    "#fill categorical columns with unkown\n",
    "cat_cols = data.columns\n",
    "print(cat_cols)\n",
    "data[cat_cols] = data[cat_cols].fillna('unknown')\n",
    "\n",
    "#print(data.isnull().sum().sort_values(ascending=False))\n",
    "#print(data.head())\n",
    "\n",
    "#group body types - Group body types into slim, average, fit, plus or unknown\n",
    "def group_body_types(bt):\n",
    "    if bt in ['thin', 'skinny']:\n",
    "        return 'slim'\n",
    "    elif bt == 'average':\n",
    "        return 'average'\n",
    "    elif bt in ['athletic', 'fit', 'jacked']: \n",
    "        return 'fit'\n",
    "    elif bt in ['a little extra', 'curvy', 'full figured', 'overweight']: \n",
    "        return 'plus'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data.body_type = data.body_type.apply(group_body_types)\n",
    "\n",
    "#Diet - for diet there are 2 pieces of info in this column, so I will divide into diet type and diet strictness\n",
    "def fill_diet_type(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1:\n",
    "        return parts[0]\n",
    "    else:\n",
    "        return parts[1]\n",
    "    \n",
    "data['diet_type'] = data['diet'].apply(fill_diet_type)\n",
    "\n",
    "def fill_diet_strictness(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1 and parts[0] == 'unknown':\n",
    "        return 'unknown'\n",
    "    elif len(parts) == 1: \n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return parts[0]\n",
    "\n",
    "data['diet_strictness'] = data['diet'].apply(fill_diet_strictness)\n",
    "\n",
    "strict_dict = {\n",
    "    'strictly': 'strict',\n",
    "    'mostly': 'flexible',\n",
    "    'neutral': 'standard',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['diet_strictness'] = data['diet_strictness'].map(strict_dict)\n",
    "\n",
    "#drinks - almost perfect, just changed some labels and grouped 2 fields\n",
    "drinks_dict = {\n",
    "    'unknown': 'unknown',\n",
    "    'not at all': 'no',\n",
    "    'rarely': 'light',\n",
    "    'socially': 'light',\n",
    "    'often': 'heavy',\n",
    "    'very often': 'heavy',\n",
    "    'desperately': 'heavy',\n",
    "}\n",
    "\n",
    "data.drinks = data.drinks.map(drinks_dict)\n",
    "\n",
    "#drugs\n",
    "#print(data.drugs.value_counts(normalize = True))\n",
    "\n",
    "drugs_map = {\n",
    "    'never': 'no',\n",
    "    'unknown': 'unknown',\n",
    "    'sometimes': 'yes',\n",
    "    'often': 'yes'\n",
    "}\n",
    "\n",
    "data['drugs'] = data['drugs'].map(drugs_map).fillna('unknown')\n",
    "#print(data.drugs.value_counts(normalize = True))\n",
    "\n",
    "#education\n",
    "\n",
    "#print(data.education.unique())\n",
    "\n",
    "def split_education(edu): \n",
    "    if edu is None or pd.isna(edu) or edu == 'unknown' or edu == '':\n",
    "        return pd.Series(['unknown', 'unknown'])\n",
    "    parts = edu.split(' ', 2)\n",
    "    if len(parts) == 1:\n",
    "        return pd.Series(['graduated from', parts[0]])\n",
    "    if len(parts) == 2:\n",
    "        return pd.Series(['graduated from', parts[0] + ' ' + parts[1]])\n",
    "    if len(parts) == 3:\n",
    "        status = parts[0] + ' ' + parts[1]\n",
    "        level = parts[2]\n",
    "        return pd.Series([status, level])\n",
    "\n",
    "data[['education_status', 'education_level']] = data['education'].apply(split_education)\n",
    "\n",
    "map_edu = {\n",
    "    'college/university': 'college',\n",
    "    'space camp': 'unknown',\n",
    "    'masters program': 'masters',\n",
    "    'two-year college': 'college',\n",
    "    'unknown': 'unknown',\n",
    "    'high school': 'high school',\n",
    "    'of space camp': 'unknown',\n",
    "    'ph.d program': 'phd',\n",
    "    'law school': 'law school',\n",
    "    'med school': 'med school',\n",
    "    'of college/university': 'college',\n",
    "    'of high school': 'high school',\n",
    "    'of ph.d program': 'phd',\n",
    "    'of two-year college': 'college',\n",
    "    'of med school': 'med school',\n",
    "    'of masters program': 'masters',\n",
    "    'of law school': 'law school'\n",
    "}\n",
    "\n",
    "edu_status_map = {\n",
    "    'working on': 'in progress',\n",
    "    'graduated from': 'finished',\n",
    "    'unknown': 'unknown',\n",
    "    'dropped out': 'dropped out'\n",
    "}\n",
    "\n",
    "data['education_level'] = data['education_level'].map(map_edu)\n",
    "data['education_status'] = data['education_status'].map(edu_status_map)\n",
    "\n",
    "#print(data.education_status.unique())\n",
    "#print(data.education_level.unique())\n",
    "\n",
    "#ethnicity\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "def get_primary_race(race):\n",
    "    if race == '' or race == 'unknown':\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return race.split(',')[0].strip().lower()\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].apply(get_primary_race)\n",
    "\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "#job\n",
    "#print(data.job.unique())\n",
    "\n",
    "career_map = {\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    \n",
    "    'medicine / health': 'Healthcare',\n",
    "    \n",
    "    'education / academia': 'Education',\n",
    "    \n",
    "    'banking / financial / real estate': 'Business',\n",
    "    'sales / marketing / biz dev': 'Business',\n",
    "    'executive / management': 'Business',\n",
    "    \n",
    "    'artistic / musical / writer': 'Creative',\n",
    "    'entertainment / media': 'Creative',\n",
    "    \n",
    "    'hospitality / travel': 'Service',\n",
    "    'clerical / administrative': 'Service',\n",
    "    'construction / craftsmanship': 'Service',\n",
    "    \n",
    "    'political / government': 'Government / Law',\n",
    "    'law / legal services': 'Government / Law',\n",
    "    'military': 'Government / Law',\n",
    "    \n",
    "    'transportation': 'Transportation',\n",
    "    \n",
    "    'student': 'Student',\n",
    "    'unemployed': 'Unemployed',\n",
    "    'retired': 'Retired',\n",
    "    \n",
    "    'rather not say': 'Other',\n",
    "    'other': 'Other',\n",
    "    'unknown': 'Other'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].map(career_map).fillna('Other')\n",
    "\n",
    "#print(data.job.unique())\n",
    "\n",
    "#last_online\n",
    "#print(data.last_online.unique())\n",
    "\n",
    "data['last_online'] = pd.to_datetime(data['last_online'], format='%Y-%m-%d-%H-%M')\n",
    "most_recent_date = data['last_online'].max()\n",
    "data['last_online'] = (most_recent_date - data['last_online']).dt.days\n",
    "\n",
    "def convert_lastonline_to_cat(lo):\n",
    "    if lo <= 7:\n",
    "        return 'active'\n",
    "    else:\n",
    "        return 'not active'\n",
    "\n",
    "data['presence'] = data['last_online'].apply(convert_lastonline_to_cat)\n",
    "\n",
    "#location\n",
    "#print(data.location.unique())\n",
    "\n",
    "def get_main_location(location):\n",
    "    return location.split(',')[1].strip()\n",
    "\n",
    "data['location'] = data['location'].apply(get_main_location)\n",
    "\n",
    "#offspring\n",
    "#print(data.offspring.unique())\n",
    "\n",
    "data['offspring'] = data['offspring'].str.replace(\"doesn&rsquo;t\", \"doesn't\", regex=False)\n",
    "\n",
    "has_kids_conditions = [\n",
    "    data['offspring'].str.contains('has a kid|has kids', case = False),\n",
    "    data['offspring'].str.contains('doesn\\'t have kids', case = False)\n",
    "]\n",
    "\n",
    "has_kids_choices = ['yes', 'no']\n",
    "\n",
    "data['has_kids'] = np.select(has_kids_conditions, has_kids_choices, default = 'unknown')\n",
    "\n",
    "wants_kids_conditions = [\n",
    "    data['offspring'].str.contains('doesn\\'t want', case=False),\n",
    "    data['offspring'].str.contains('might want', case=False),\n",
    "    data['offspring'].str.contains('wants', case=False)\n",
    "]\n",
    " \n",
    "wants_kids_choices = ['no', 'maybe', 'yes']\n",
    "\n",
    "data['wants_kids'] = np.select(wants_kids_conditions, wants_kids_choices, default='unknown')\n",
    "\n",
    "#orientation - already good\n",
    "#print(data.orientation.value_counts())\n",
    "\n",
    "orientation_map = {\n",
    "    'straight' : 'straight',\n",
    "    'gay': 'queer',\n",
    "    'bisexual': 'queer'\n",
    "}\n",
    "\n",
    "data['orientation'] = data['orientation'].map(orientation_map).fillna('unknown')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pets\n",
    "#print(data.pets.unique())\n",
    "\n",
    "likes_dogs_conditions = [\n",
    "    data['pets'].str.contains('likes dogs', case = False),\n",
    "    data['pets'].str.contains('dislikes dogs', case = False)\n",
    "]\n",
    "\n",
    "likes_dogs_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_dogs'] = np.select(likes_dogs_conditions, likes_dogs_choices, default = 'unknown')\n",
    "\n",
    "has_dogs_conditions = [\n",
    "    data['pets'].str.contains('has dogs', case = False)\n",
    "]\n",
    "\n",
    "has_dogs_choices = ['yes']\n",
    "\n",
    "data['has_dogs'] = np.select(has_dogs_conditions, has_dogs_choices, default = 'unknown')\n",
    "\n",
    "likes_cats_conditions = [\n",
    "    data['pets'].str.contains('likes cats', case = False),\n",
    "    data['pets'].str.contains('dislikes cats', case = False)\n",
    "]\n",
    "\n",
    "likes_cats_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_cats'] = np.select(likes_cats_conditions, likes_cats_choices, default = 'unknown')\n",
    "\n",
    "has_cats_conditions = [\n",
    "    data['pets'].str.contains('has cats', case = False)\n",
    "]\n",
    "\n",
    "has_cats_choices = ['yes']\n",
    "\n",
    "data['has_cats'] = np.select(has_cats_conditions, has_cats_choices, default = 'unknown')\n",
    "\n",
    "# religion\n",
    "#print(data.religion.unique())\n",
    "\n",
    "religion_dedication_condition = [\n",
    "    data['religion'].str.contains('very serious', case = False),\n",
    "    data['religion'].str.contains('not too serious', case = False),\n",
    "    data['religion'].str.contains('somewhat', case = False),\n",
    "    data['religion'].str.contains('laughing', case = False)\n",
    "]\n",
    "\n",
    "religion_dedication_values = ['yes', 'yes', 'yes', 'no']\n",
    "\n",
    "data['religion_dedication'] = np.select(religion_dedication_condition, religion_dedication_values, default = 'unknown')\n",
    "\n",
    "def set_religion(r):\n",
    "    return r.split(' ', 2)[0]\n",
    "\n",
    "data['religion'] = data.religion.apply(set_religion)\n",
    "\n",
    "#sex - no changes needed\n",
    "#print(data.sex.unique())\n",
    "\n",
    "#sign \n",
    "#print(data.sign.unique())\n",
    "\n",
    "data['sign'] = data['sign'].str.replace('doesn&rsquo;t', 'doesn\\'t', regex=False)\n",
    "data['sign'] = data['sign'].str.replace('it&rsquo;s', 'it\\'s', regex=False)\n",
    "\n",
    "sign_importance_conditions = [\n",
    "    data['sign'].str.contains('doesn\\'t matter', case = False),\n",
    "    data['sign'].str.contains('fun', case = False),\n",
    "    data['sign'].str.contains('it matters', case = False)\n",
    "]\n",
    "\n",
    "sign_importance_options = ['no', 'no', 'yes']\n",
    "\n",
    "data['sign_importance'] = np.select(sign_importance_conditions, sign_importance_options, default = 'unknown')\n",
    "\n",
    "def set_sign(sign):\n",
    "    return sign.split(' ', 2)[0]\n",
    "\n",
    "data['sign'] = data['sign'].apply(set_sign)\n",
    "\n",
    "#smokes\n",
    "#print(data.smokes.value_counts(normalize=True))\n",
    "\n",
    "map_smoking = {\n",
    "    'when drinking': 'yes',\n",
    "    'trying to quit': 'yes',\n",
    "    'sometimes': 'yes',\n",
    "    'no': 'no',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data.smokes = data.smokes.map(map_smoking)\n",
    "#print(data.smokes.value_counts(normalize=True))\n",
    "\n",
    "#speaks\n",
    "#print(data.speaks.unique())\n",
    "\n",
    "\"\"\"\n",
    "language_counts = {}\n",
    "for record in data.speaks.unique():\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l in language_counts:\n",
    "            language_counts[l] += 1\n",
    "        else:\n",
    "            language_counts[l] = 1\n",
    "\n",
    "sorted_langs = dict(sorted(language_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\"\"\"\n",
    "\n",
    "#decided for now to only store the number of languages spoken\n",
    "\n",
    "def get_language_count(record):\n",
    "    language_count = 0\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l not in ['c++', 'lisp', 'ancient', 'unknown', 'sign']:\n",
    "            language_count += 1\n",
    "    return language_count\n",
    "\n",
    "data['languages_count'] = data['speaks'].apply(get_language_count)\n",
    "#print(data[['languages_count', 'speaks']].head())\n",
    "\n",
    "#Next step: add 1 column for each of the top 10 and add the level for each user\n",
    "\n",
    "#status\n",
    "#print(data.status.value_counts(normalize=True))\n",
    "\n",
    "status_map = {\n",
    "    'single': 'single',\n",
    "    'available': 'single',\n",
    "    'seeing someone': 'committed',\n",
    "    'married': 'committed',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['status'] = data['status'].map(status_map)\n",
    "#print(data.status.value_counts(normalize=True))\n",
    "\n",
    "#numerical fields\n",
    "#print(data.describe())\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "data['height'].hist(bins=30)\n",
    "plt.xlabel('Height (inches)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data['age'].hist(bins=30)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "data = data[(data['age'] >= 18) & (data['age'] <= 90)] # reasonable interval for age\n",
    "data = data[(data['height'] >= 54) & (data['height'] <= 84)] # reasonable interval for height\n",
    "\n",
    "data = data.drop(columns=['income']) #around 80% of values are missing, will just drop the column\n",
    "\n",
    "# still need to drop: diet, education, last_online, offspring, pets, speaks -> other columns were created based on this information\n",
    "\n",
    "data = data.drop(columns=['diet', 'education', 'last_online', 'offspring', 'pets', 'speaks'])\n",
    "\n",
    "#now drop columns where unknowns are more than 50%\n",
    "\n",
    "cat_cols = data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "threshold = 0.5\n",
    "high_unknown_cols = []\n",
    "for col in cat_cols:\n",
    "    p = (data[col] == 'unknown').mean()\n",
    "    if p > threshold:\n",
    "        high_unknown_cols.append(col)\n",
    "\n",
    "#print(high_unknown_cols)\n",
    "\n",
    "\n",
    "# drop dominant columns\n",
    "def drop_dominant_columns(df, threshold=0.95):\n",
    "    drop_cols = []\n",
    "    for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "        top_freq = df[col].value_counts(normalize=True).iloc[0]\n",
    "        if top_freq > threshold:\n",
    "            drop_cols.append(col)\n",
    "    print('will drop ', drop_cols)\n",
    "    return df.drop(columns=drop_cols), drop_cols\n",
    "\n",
    "data, dropped = drop_dominant_columns(data, threshold=0.95)\n",
    "print(f\"Dropped columns due to dominance: {dropped}\")\n",
    "\n",
    "data = data.drop(columns=high_unknown_cols)\n",
    "\n",
    "not_essay_cols = [col for col in data.columns if 'essay' not in col]\n",
    "print(data[not_essay_cols].head())\n",
    "print(data[not_essay_cols].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper module with funtions\n",
    "\n",
    "def downsample(df, col):\n",
    "    min_count = df[col].value_counts().min()\n",
    "    balanced_df = pd.concat([\n",
    "        df[df[col] == category].sample(n=min_count, random_state=1)\n",
    "        for category in df[col].unique()\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample(df, target_col):\n",
    "    # Split into majority and minority classes\n",
    "    classes = df[target_col].value_counts().index\n",
    "    max_count = df[target_col].value_counts().max()\n",
    "\n",
    "    df_upsampled = []\n",
    "\n",
    "    for cls in classes:\n",
    "        df_class = df[df[target_col] == cls]\n",
    "        df_class_upsampled = resample(\n",
    "            df_class,\n",
    "            replace=True,               # Sample with replacement\n",
    "            n_samples=max_count,        # Match majority class\n",
    "            random_state=42\n",
    "        )\n",
    "        df_upsampled.append(df_class_upsampled)\n",
    "\n",
    "    return pd.concat(df_upsampled).sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type\n",
      "fit        0.416228\n",
      "average    0.244609\n",
      "plus       0.133604\n",
      "slim       0.108333\n",
      "unknown    0.097226\n",
      "Name: proportion, dtype: float64\n",
      "drinks\n",
      "light      0.796796\n",
      "heavy      0.099146\n",
      "no         0.054467\n",
      "unknown    0.049590\n",
      "Name: proportion, dtype: float64\n",
      "drugs\n",
      "no         0.629503\n",
      "unknown    0.234838\n",
      "yes        0.135658\n",
      "Name: proportion, dtype: float64\n",
      "ethnicity\n",
      "white               0.558735\n",
      "asian               0.136828\n",
      "unknown             0.094603\n",
      "hispanic / latin    0.072990\n",
      "black               0.051244\n",
      "other               0.028328\n",
      "indian              0.019976\n",
      "middle eastern      0.013529\n",
      "pacific islander    0.011942\n",
      "native american     0.011825\n",
      "Name: proportion, dtype: float64\n",
      "job\n",
      "Other               0.270482\n",
      "STEM                0.159476\n",
      "Business            0.150741\n",
      "Creative            0.111607\n",
      "Student             0.081392\n",
      "Healthcare          0.061432\n",
      "Education           0.058609\n",
      "Service             0.053248\n",
      "Government / Law    0.038232\n",
      "Transportation      0.006113\n",
      "Unemployed          0.004526\n",
      "Retired             0.004142\n",
      "Name: proportion, dtype: float64\n",
      "orientation\n",
      "straight    0.860801\n",
      "queer       0.139199\n",
      "Name: proportion, dtype: float64\n",
      "religion\n",
      "unknown         0.337409\n",
      "agnosticism     0.146999\n",
      "other           0.129061\n",
      "atheism         0.116551\n",
      "christianity    0.096558\n",
      "catholicism     0.079437\n",
      "judaism         0.051678\n",
      "buddhism        0.032503\n",
      "hinduism        0.007516\n",
      "islam           0.002288\n",
      "Name: proportion, dtype: float64\n",
      "sex\n",
      "m    0.597618\n",
      "f    0.402382\n",
      "Name: proportion, dtype: float64\n",
      "sign\n",
      "unknown        0.184330\n",
      "leo            0.072940\n",
      "gemini         0.071905\n",
      "libra          0.070201\n",
      "cancer         0.070184\n",
      "virgo          0.069132\n",
      "taurus         0.069032\n",
      "scorpio        0.068965\n",
      "aries          0.066593\n",
      "pisces         0.065808\n",
      "sagittarius    0.065775\n",
      "aquarius       0.065524\n",
      "capricorn      0.059611\n",
      "Name: proportion, dtype: float64\n",
      "smokes\n",
      "no         0.760755\n",
      "yes        0.143873\n",
      "unknown    0.095372\n",
      "Name: proportion, dtype: float64\n",
      "diet_type\n",
      "anything      0.465334\n",
      "unknown       0.406775\n",
      "vegetarian    0.083229\n",
      "other         0.029731\n",
      "vegan         0.011725\n",
      "kosher        0.001921\n",
      "halal         0.001286\n",
      "Name: proportion, dtype: float64\n",
      "diet_strictness\n",
      "unknown     0.406775\n",
      "flexible    0.358872\n",
      "standard    0.122530\n",
      "strict      0.111824\n",
      "Name: proportion, dtype: float64\n",
      "education_status\n",
      "finished       0.679895\n",
      "in progress    0.174609\n",
      "unknown        0.110437\n",
      "dropped out    0.035059\n",
      "Name: proportion, dtype: float64\n",
      "education_level\n",
      "college        0.575537\n",
      "masters        0.182292\n",
      "unknown        0.138364\n",
      "phd            0.040136\n",
      "high school    0.028495\n",
      "law school     0.023801\n",
      "med school     0.011374\n",
      "Name: proportion, dtype: float64\n",
      "presence\n",
      "active        0.608692\n",
      "not active    0.391308\n",
      "Name: proportion, dtype: float64\n",
      "sign_importance\n",
      "no         0.602145\n",
      "unknown    0.386681\n",
      "yes        0.011174\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check class imbalance\n",
    "\n",
    "cols = data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cols = [col for col in cols if 'essay' not in col]\n",
    "\n",
    "for column in cols:\n",
    "    print(data[column].value_counts(normalize = True)) #check if the classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "m    0.597618\n",
      "f    0.402382\n",
      "Name: proportion, dtype: float64\n",
      "sex\n",
      "m    0.597618\n",
      "f    0.402382\n",
      "Name: proportion, dtype: float64\n",
      "['f' 'm']\n",
      "Selected features from Chi2: ['age', 'height', 'body_type_fit', 'body_type_plus', 'job_Education', 'job_Healthcare', 'job_STEM', 'religion_atheism', 'diet_type_vegetarian', 'education_level_masters']\n",
      "1    0.597628\n",
      "0    0.402372\n",
      "Name: proportion, dtype: float64\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Classification report for XGB Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80      4819\n",
      "           1       0.84      0.92      0.88      7156\n",
      "\n",
      "    accuracy                           0.85     11975\n",
      "   macro avg       0.86      0.83      0.84     11975\n",
      "weighted avg       0.85      0.85      0.85     11975\n",
      "\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Classification report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      4819\n",
      "           1       0.88      0.86      0.87      7156\n",
      "\n",
      "    accuracy                           0.85     11975\n",
      "   macro avg       0.85      0.85      0.85     11975\n",
      "weighted avg       0.85      0.85      0.85     11975\n",
      "\n",
      "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.84164014        nan 0.84520051 0.84525418 0.84583298        nan\n",
      " 0.8457857  0.84584915 0.84588879        nan 0.84584122 0.84584591\n",
      " 0.84578229        nan 0.84578229 0.84584841]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = data[not_essay_cols].copy()\n",
    "col_to_predict = 'sex'\n",
    "\n",
    "#remove rows where the target variable is unknown\n",
    "df = df[df[col_to_predict] != 'unknown']\n",
    "df = df[df[col_to_predict].notna()]\n",
    "\n",
    "#create vars with categorical columns and numerical columns\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col != col_to_predict]\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "num_cols = [col for col in num_cols if col != col_to_predict]\n",
    "\n",
    "df_dummies = pd.get_dummies(df[cat_cols], drop_first = True)\n",
    "\n",
    "x = pd.concat([df[num_cols], df_dummies], axis = 1)\n",
    "y = df[col_to_predict]\n",
    "\n",
    "print(df[col_to_predict].value_counts(normalize = True)) #check if the classes are balanced\n",
    "print(y.value_counts(normalize = True)) #check if the classes are balanced\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "\n",
    "# ------------ Chi2 test ------------ #\n",
    "# Chi2 requires all values to be non-negative\n",
    "X_chi = x.copy()\n",
    "X_chi[X_chi < 0] = 0  # Only necessary if you have negative values\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=10)  # Keep top 10 features\n",
    "X_chi_selected = selector.fit_transform(X_chi, y)\n",
    "selected_features = X_chi.columns[selector.get_support()]\n",
    "print(f\"Selected features from Chi2: {list(selected_features)}\")\n",
    "\n",
    "x = x[selected_features]\n",
    "\n",
    "cat_cols = x.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = x.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# ------------ End of Chi2 test ------------ #\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=24, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[num_cols] = scaler.fit_transform(x_train[num_cols])\n",
    "x_test[num_cols] = scaler.transform(x_test[num_cols]) #never use fit transform on test data, because it will learn from train data\n",
    "\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "# ----- XGB Classifier ----- #\n",
    "counter = Counter(y_train)\n",
    "majority = max(counter.values())\n",
    "minority = min(counter.values())\n",
    "imbalance_ratio = majority / minority\n",
    "\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=imbalance_ratio\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_macro', verbose=1, n_jobs=-1)    \n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "y_pred = gs.predict(x_test)\n",
    "print('Classification report for XGB Classifier:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------- Logistic Regression ------------- #\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter = 1000)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],             # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs'] # Type of regularization\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "y_pred_model = gs.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred_model)\n",
    "print('Classification report for LR:')\n",
    "print(model_score)\n",
    "print(\"Best Parameters:\", gs.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Stuff not used\n",
    "\n",
    "'''\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight='balanced')\n",
    "print('1')\n",
    "model.fit(x_train, y_train)\n",
    "print('2')\n",
    "y_pred = model.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred)\n",
    "print('Classification report SVC:')\n",
    "print(model_score)\n",
    "\n",
    "#DO FEATURE SELECTION\n",
    "#DO HYPERPARAMETER TUNING\n",
    "#DO CLASS MERGE (IF NEEDED)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "model = LogisticRegression(class_weight='balanced', solver = 'lbfgs', max_iter = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_model = model.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred_model)\n",
    "print('Classification report for LR:')\n",
    "print(model_score)\n",
    "'''\n",
    "\n",
    "'''\n",
    "smote = SMOTE(random_state=24)\n",
    "x_resampled, y_resampled = smote.fit_resample(x_train, y_train) #use SMOTE to make sure the classes are balanced\n",
    "'''\n",
    "\n",
    "'''\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "x = selector.fit_transform(x)\n",
    "'''\n",
    "\n",
    "# -------- Apply downsampling to make sure the classes are balanced --------------\n",
    "'''\n",
    "# Convert y_train back to Series with the correct index\n",
    "y_train_series = pd.Series(y_train, index=x_train.index, name=col_to_predict)\n",
    "\n",
    "# Concatenate features and target\n",
    "train_data = pd.concat([x_train, y_train_series], axis=1)\n",
    "\n",
    "train_balanced = downsample(train_data, col_to_predict)\n",
    "x_train = train_balanced.drop(columns = col_to_predict)\n",
    "y_train = train_balanced[col_to_predict]\n",
    "'''\n",
    "# -------- Downsampling ends here --------------\n",
    "\n",
    "# ----- Random forests ----- #\n",
    "'''\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "rf_score = classification_report(y_test, y_pred_rf)\n",
    "print('Classification report for RF:')\n",
    "print(rf_score)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=x_train.columns)\n",
    "print(importances.sort_values(ascending=False).head(10))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
