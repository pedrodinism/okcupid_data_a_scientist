{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age       body_type               diet    drinks      drugs  \\\n",
      "0   22  a little extra  strictly anything  socially      never   \n",
      "1   35         average       mostly other     often  sometimes   \n",
      "2   38            thin           anything  socially        NaN   \n",
      "3   23            thin         vegetarian  socially        NaN   \n",
      "4   29        athletic                NaN  socially      never   \n",
      "\n",
      "                           education            ethnicity  height  income  \\\n",
      "0      working on college/university         asian, white    75.0      -1   \n",
      "1              working on space camp                white    70.0   80000   \n",
      "2     graduated from masters program                  NaN    68.0      -1   \n",
      "3      working on college/university                white    71.0   20000   \n",
      "4  graduated from college/university  asian, black, other    66.0      -1   \n",
      "\n",
      "                           job  ...                         location  \\\n",
      "0               transportation  ...  south san francisco, california   \n",
      "1         hospitality / travel  ...              oakland, california   \n",
      "2                          NaN  ...        san francisco, california   \n",
      "3                      student  ...             berkeley, california   \n",
      "4  artistic / musical / writer  ...        san francisco, california   \n",
      "\n",
      "                                      offspring orientation  \\\n",
      "0  doesn&rsquo;t have kids, but might want them    straight   \n",
      "1  doesn&rsquo;t have kids, but might want them    straight   \n",
      "2                                           NaN    straight   \n",
      "3                       doesn&rsquo;t want kids    straight   \n",
      "4                                           NaN    straight   \n",
      "\n",
      "                        pets                                  religion sex  \\\n",
      "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
      "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
      "2                   has cats                                       NaN   m   \n",
      "3                 likes cats                                       NaN   m   \n",
      "4  likes dogs and likes cats                                       NaN   m   \n",
      "\n",
      "                                 sign     smokes  \\\n",
      "0                              gemini  sometimes   \n",
      "1                              cancer         no   \n",
      "2  pisces but it doesn&rsquo;t matter         no   \n",
      "3                              pisces         no   \n",
      "4                            aquarius         no   \n",
      "\n",
      "                                              speaks     status  \n",
      "0                                            english     single  \n",
      "1  english (fluently), spanish (poorly), french (...     single  \n",
      "2                               english, french, c++  available  \n",
      "3                           english, german (poorly)     single  \n",
      "4                                            english     single  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "                age        height          income\n",
      "count  59946.000000  59943.000000    59946.000000\n",
      "mean      32.340290     68.295281    20033.222534\n",
      "std        9.452779      3.994803    97346.192104\n",
      "min       18.000000      1.000000       -1.000000\n",
      "25%       26.000000     66.000000       -1.000000\n",
      "50%       30.000000     68.000000       -1.000000\n",
      "75%       37.000000     71.000000       -1.000000\n",
      "max      110.000000     95.000000  1000000.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   ethnicity    54266 non-null  object \n",
      " 7   height       59943 non-null  float64\n",
      " 8   income       59946 non-null  int64  \n",
      " 9   job          51748 non-null  object \n",
      " 10  last_online  59946 non-null  object \n",
      " 11  location     59946 non-null  object \n",
      " 12  offspring    24385 non-null  object \n",
      " 13  orientation  59946 non-null  object \n",
      " 14  pets         40025 non-null  object \n",
      " 15  religion     39720 non-null  object \n",
      " 16  sex          59946 non-null  object \n",
      " 17  sign         48890 non-null  object \n",
      " 18  smokes       54434 non-null  object \n",
      " 19  speaks       59896 non-null  object \n",
      " 20  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n",
      "None\n",
      "(59946, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('profiles.csv')\n",
    "\n",
    "not_essay_cols = [col for col in data.columns if 'essay' not in col]\n",
    "data = data[not_essay_cols]\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "print(data.info())\n",
    "print(data.shape)\n",
    "#print(data.duplicated())\n",
    "#data.isnull().mean().sort_values(ascending=False)  # for percentage\n",
    "#data.isnull().sum().sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
      "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
      "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
      "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
      "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
      "      dtype='object')\n",
      "will drop  ['location', 'status']\n",
      "Dropped columns due to dominance: ['location', 'status']\n",
      "   age body_type    drinks      drugs ethnicity  height             job  \\\n",
      "0   22      plus  moderate      never     asian    75.0  Transportation   \n",
      "1   35   average     heavy  sometimes     white    70.0         Service   \n",
      "2   38      slim  moderate    unknown   unknown    68.0           Other   \n",
      "3   23      slim  moderate    unknown     white    71.0         Student   \n",
      "4   29       fit  moderate      never     asian    66.0        Creative   \n",
      "\n",
      "  orientation     religion sex      sign     smokes   diet_type  \\\n",
      "0    straight  agnosticism   m    gemini  sometimes    anything   \n",
      "1    straight  agnosticism   m    cancer         no       other   \n",
      "2    straight      unknown   m    pisces         no    anything   \n",
      "3    straight      unknown   m    pisces         no  vegetarian   \n",
      "4    straight      unknown   m  aquarius         no     unknown   \n",
      "\n",
      "  diet_strictness education_status education_level presence sign_importance  \\\n",
      "0          strict      in progress         college   active         unknown   \n",
      "1        flexible      in progress         unknown   active         unknown   \n",
      "2        standard         finished         masters   active   not important   \n",
      "3        standard      in progress         college   active         unknown   \n",
      "4         unknown         finished         college   active         unknown   \n",
      "\n",
      "   languages_count  \n",
      "0                1  \n",
      "1                3  \n",
      "2                2  \n",
      "3                2  \n",
      "4                1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59871 entries, 0 to 59945\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               59871 non-null  int64  \n",
      " 1   body_type         59871 non-null  object \n",
      " 2   drinks            59871 non-null  object \n",
      " 3   drugs             59871 non-null  object \n",
      " 4   ethnicity         59871 non-null  object \n",
      " 5   height            59871 non-null  float64\n",
      " 6   job               59871 non-null  object \n",
      " 7   orientation       59871 non-null  object \n",
      " 8   religion          59871 non-null  object \n",
      " 9   sex               59871 non-null  object \n",
      " 10  sign              59871 non-null  object \n",
      " 11  smokes            59871 non-null  object \n",
      " 12  diet_type         59871 non-null  object \n",
      " 13  diet_strictness   59871 non-null  object \n",
      " 14  education_status  59871 non-null  object \n",
      " 15  education_level   59871 non-null  object \n",
      " 16  presence          59871 non-null  object \n",
      " 17  sign_importance   59871 non-null  object \n",
      " 18  languages_count   59871 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(16)\n",
      "memory usage: 9.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('profiles.csv')\n",
    "\n",
    "#EDA\n",
    "\n",
    "#fill null essays with empty string\n",
    "essay_cols = [col for col in data.columns if 'essay' in col]\n",
    "data[essay_cols] = data[essay_cols].fillna('')\n",
    "\n",
    "#drop 3 records without height (was thinking about filling those values with the mean, but since there are only 3 rows, decided to drop them)\n",
    "data = data.dropna(subset=['height'])\n",
    "\n",
    "#fill categorical columns with unkown\n",
    "cat_cols = data.columns\n",
    "print(cat_cols)\n",
    "data[cat_cols] = data[cat_cols].fillna('unknown')\n",
    "\n",
    "#print(data.isnull().sum().sort_values(ascending=False))\n",
    "#print(data.head())\n",
    "\n",
    "#group body types - Group body types into slim, average, fit, plus or unknown\n",
    "def group_body_types(bt):\n",
    "    if bt in ['thin', 'skinny']:\n",
    "        return 'slim'\n",
    "    elif bt == 'average':\n",
    "        return 'average'\n",
    "    elif bt in ['athletic', 'fit', 'jacked']: \n",
    "        return 'fit'\n",
    "    elif bt in ['a little extra', 'curvy', 'full figured', 'overweight']: \n",
    "        return 'plus'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data.body_type = data.body_type.apply(group_body_types)\n",
    "\n",
    "#Diet - for diet there are 2 pieces of info in this column, so I will divide into diet type and diet strictness\n",
    "def fill_diet_type(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1:\n",
    "        return parts[0]\n",
    "    else:\n",
    "        return parts[1]\n",
    "    \n",
    "data['diet_type'] = data['diet'].apply(fill_diet_type)\n",
    "\n",
    "def fill_diet_strictness(diet):\n",
    "    parts = diet.split(' ')\n",
    "    if len(parts) == 1 and parts[0] == 'unknown':\n",
    "        return 'unknown'\n",
    "    elif len(parts) == 1: \n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return parts[0]\n",
    "\n",
    "data['diet_strictness'] = data['diet'].apply(fill_diet_strictness)\n",
    "\n",
    "strict_dict = {\n",
    "    'strictly': 'strict',\n",
    "    'mostly': 'flexible',\n",
    "    'neutral': 'standard',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['diet_strictness'] = data['diet_strictness'].map(strict_dict)\n",
    "\n",
    "#drinks - almost perfect, just changed some labels and grouped 2 fields\n",
    "drinks_dict = {\n",
    "    'unknown': 'unknown',\n",
    "    'not at all': 'non-drinker',\n",
    "    'rarely': 'light',\n",
    "    'socially': 'moderate',\n",
    "    'often': 'heavy',\n",
    "    'very often': 'heavy',\n",
    "    'desperately': 'very heavy',    \n",
    "}\n",
    "\n",
    "data.drinks = data.drinks.map(drinks_dict)\n",
    "\n",
    "#drugs - good to go\n",
    "#education\n",
    "\n",
    "#print(data.education.unique())\n",
    "\n",
    "def split_education(edu): \n",
    "    if edu is None or pd.isna(edu) or edu == 'unknown' or edu == '':\n",
    "        return pd.Series(['unknown', 'unknown'])\n",
    "    parts = edu.split(' ', 2)\n",
    "    if len(parts) == 1:\n",
    "        return pd.Series(['graduated from', parts[0]])\n",
    "    if len(parts) == 2:\n",
    "        return pd.Series(['graduated from', parts[0] + ' ' + parts[1]])\n",
    "    if len(parts) == 3:\n",
    "        status = parts[0] + ' ' + parts[1]\n",
    "        level = parts[2]\n",
    "        return pd.Series([status, level])\n",
    "\n",
    "data[['education_status', 'education_level']] = data['education'].apply(split_education)\n",
    "\n",
    "map_edu = {\n",
    "    'college/university': 'college',\n",
    "    'space camp': 'unknown',\n",
    "    'masters program': 'masters',\n",
    "    'two-year college': 'college',\n",
    "    'unknown': 'unknown',\n",
    "    'high school': 'high school',\n",
    "    'of space camp': 'unknown',\n",
    "    'ph.d program': 'phd',\n",
    "    'law school': 'law school',\n",
    "    'med school': 'med school',\n",
    "    'of college/university': 'college',\n",
    "    'of high school': 'high school',\n",
    "    'of ph.d program': 'phd',\n",
    "    'of two-year college': 'college',\n",
    "    'of med school': 'med school',\n",
    "    'of masters program': 'masters',\n",
    "    'of law school': 'law school'\n",
    "}\n",
    "\n",
    "edu_status_map = {\n",
    "    'working on': 'in progress',\n",
    "    'graduated from': 'finished',\n",
    "    'unknown': 'unknown',\n",
    "    'dropped out': 'dropped out'\n",
    "}\n",
    "\n",
    "data['education_level'] = data['education_level'].map(map_edu)\n",
    "data['education_status'] = data['education_status'].map(edu_status_map)\n",
    "\n",
    "#print(data.education_status.unique())\n",
    "#print(data.education_level.unique())\n",
    "\n",
    "#ethnicity\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "def get_primary_race(race):\n",
    "    if race == '' or race == 'unknown':\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return race.split(',')[0].strip().lower()\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].apply(get_primary_race)\n",
    "\n",
    "#print(data.ethnicity.unique())\n",
    "\n",
    "#job\n",
    "#print(data.job.unique())\n",
    "\n",
    "career_map = {\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    \n",
    "    'medicine / health': 'Healthcare',\n",
    "    \n",
    "    'education / academia': 'Education',\n",
    "    \n",
    "    'banking / financial / real estate': 'Business',\n",
    "    'sales / marketing / biz dev': 'Business',\n",
    "    'executive / management': 'Business',\n",
    "    \n",
    "    'artistic / musical / writer': 'Creative',\n",
    "    'entertainment / media': 'Creative',\n",
    "    \n",
    "    'hospitality / travel': 'Service',\n",
    "    'clerical / administrative': 'Service',\n",
    "    'construction / craftsmanship': 'Service',\n",
    "    \n",
    "    'political / government': 'Government / Law',\n",
    "    'law / legal services': 'Government / Law',\n",
    "    'military': 'Government / Law',\n",
    "    \n",
    "    'transportation': 'Transportation',\n",
    "    \n",
    "    'student': 'Student',\n",
    "    'unemployed': 'Unemployed',\n",
    "    'retired': 'Retired',\n",
    "    \n",
    "    'rather not say': 'Other',\n",
    "    'other': 'Other',\n",
    "    'unknown': 'Other'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].map(career_map).fillna('Other')\n",
    "\n",
    "#print(data.job.unique())\n",
    "\n",
    "#last_online\n",
    "#print(data.last_online.unique())\n",
    "\n",
    "data['last_online'] = pd.to_datetime(data['last_online'], format='%Y-%m-%d-%H-%M')\n",
    "most_recent_date = data['last_online'].max()\n",
    "data['last_online'] = (most_recent_date - data['last_online']).dt.days\n",
    "\n",
    "def convert_lastonline_to_cat(lo):\n",
    "    if lo <= 7:\n",
    "        return 'active'\n",
    "    elif lo < 14:\n",
    "        return 'semi-active'\n",
    "    else:\n",
    "        return 'not active'\n",
    "\n",
    "data['presence'] = data['last_online'].apply(convert_lastonline_to_cat)\n",
    "\n",
    "#location\n",
    "#print(data.location.unique())\n",
    "\n",
    "def get_main_location(location):\n",
    "    return location.split(',')[1].strip()\n",
    "\n",
    "data['location'] = data['location'].apply(get_main_location)\n",
    "\n",
    "#offspring\n",
    "#print(data.offspring.unique())\n",
    "\n",
    "data['offspring'] = data['offspring'].str.replace(\"doesn&rsquo;t\", \"doesn't\", regex=False)\n",
    "\n",
    "has_kids_conditions = [\n",
    "    data['offspring'].str.contains('has a kid|has kids', case = False),\n",
    "    data['offspring'].str.contains('doesn\\'t have kids', case = False)\n",
    "]\n",
    "\n",
    "has_kids_choices = ['yes', 'no']\n",
    "\n",
    "data['has_kids'] = np.select(has_kids_conditions, has_kids_choices, default = 'unknown')\n",
    "\n",
    "wants_kids_conditions = [\n",
    "    data['offspring'].str.contains('doesn\\'t want', case=False),\n",
    "    data['offspring'].str.contains('might want', case=False),\n",
    "    data['offspring'].str.contains('wants', case=False)\n",
    "]\n",
    " \n",
    "wants_kids_choices = ['no', 'maybe', 'yes']\n",
    "\n",
    "data['wants_kids'] = np.select(wants_kids_conditions, wants_kids_choices, default='unknown')\n",
    "\n",
    "#orientation - already good\n",
    "#print(data.orientation.unique())\n",
    "\n",
    "#pets\n",
    "#print(data.pets.unique())\n",
    "\n",
    "likes_dogs_conditions = [\n",
    "    data['pets'].str.contains('likes dogs', case = False),\n",
    "    data['pets'].str.contains('dislikes dogs', case = False)\n",
    "]\n",
    "\n",
    "likes_dogs_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_dogs'] = np.select(likes_dogs_conditions, likes_dogs_choices, default = 'unknown')\n",
    "\n",
    "has_dogs_conditions = [\n",
    "    data['pets'].str.contains('has dogs', case = False)\n",
    "]\n",
    "\n",
    "has_dogs_choices = ['yes']\n",
    "\n",
    "data['has_dogs'] = np.select(has_dogs_conditions, has_dogs_choices, default = 'unknown')\n",
    "\n",
    "likes_cats_conditions = [\n",
    "    data['pets'].str.contains('likes cats', case = False),\n",
    "    data['pets'].str.contains('dislikes cats', case = False)\n",
    "]\n",
    "\n",
    "likes_cats_choices = ['yes', 'no']\n",
    "\n",
    "data['likes_cats'] = np.select(likes_cats_conditions, likes_cats_choices, default = 'unknown')\n",
    "\n",
    "has_cats_conditions = [\n",
    "    data['pets'].str.contains('has cats', case = False)\n",
    "]\n",
    "\n",
    "has_cats_choices = ['yes']\n",
    "\n",
    "data['has_cats'] = np.select(has_cats_conditions, has_cats_choices, default = 'unknown')\n",
    "\n",
    "# religion\n",
    "#print(data.religion.unique())\n",
    "\n",
    "religion_dedication_condition = [\n",
    "    data['religion'].str.contains('very serious', case = False),\n",
    "    data['religion'].str.contains('not too serious', case = False),\n",
    "    data['religion'].str.contains('somewhat', case = False),\n",
    "    data['religion'].str.contains('laughing', case = False)\n",
    "]\n",
    "\n",
    "religion_dedication_values = ['very dedicated', 'dedicated', 'partially dedicated', 'not dedicated']\n",
    "\n",
    "data['religion_dedication'] = np.select(religion_dedication_condition, religion_dedication_values, default = 'unknown')\n",
    "\n",
    "def set_religion(r):\n",
    "    return r.split(' ', 2)[0]\n",
    "\n",
    "data['religion'] = data.religion.apply(set_religion)\n",
    "\n",
    "#sex - no changes needed\n",
    "#print(data.sex.unique())\n",
    "\n",
    "#sign \n",
    "#print(data.sign.unique())\n",
    "\n",
    "data['sign'] = data['sign'].str.replace('doesn&rsquo;t', 'doesn\\'t', regex=False)\n",
    "data['sign'] = data['sign'].str.replace('it&rsquo;s', 'it\\'s', regex=False)\n",
    "\n",
    "sign_importance_conditions = [\n",
    "    data['sign'].str.contains('doesn\\'t matter', case = False),\n",
    "    data['sign'].str.contains('fun', case = False),\n",
    "    data['sign'].str.contains('it matters', case = False)\n",
    "]\n",
    "\n",
    "sign_importance_options = ['not important', 'fun', 'important']\n",
    "\n",
    "data['sign_importance'] = np.select(sign_importance_conditions, sign_importance_options, default = 'unknown')\n",
    "\n",
    "def set_sign(sign):\n",
    "    return sign.split(' ', 2)[0]\n",
    "\n",
    "data['sign'] = data['sign'].apply(set_sign)\n",
    "\n",
    "#smokes\n",
    "#print(data.smokes.unique())\n",
    "\n",
    "map_smoking = {\n",
    "    'when drinking': 'sometimes',\n",
    "    'trying to quit': 'yes'\n",
    "}\n",
    "\n",
    "data['smokes'] = data['smokes'].replace(map_smoking)\n",
    "\n",
    "#speaks\n",
    "#print(data.speaks.unique())\n",
    "\n",
    "\"\"\"\n",
    "language_counts = {}\n",
    "for record in data.speaks.unique():\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l in language_counts:\n",
    "            language_counts[l] += 1\n",
    "        else:\n",
    "            language_counts[l] = 1\n",
    "\n",
    "sorted_langs = dict(sorted(language_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\"\"\"\n",
    "\n",
    "#decided for now to only store the number of languages spoken\n",
    "\n",
    "def get_language_count(record):\n",
    "    language_count = 0\n",
    "    languages = record.split(',')\n",
    "    for lang in languages:\n",
    "        l = lang.strip().split(' ')[0]\n",
    "        if l not in ['c++', 'lisp', 'ancient', 'unknown', 'sign']:\n",
    "            language_count += 1\n",
    "    return language_count\n",
    "\n",
    "data['languages_count'] = data['speaks'].apply(get_language_count)\n",
    "#print(data[['languages_count', 'speaks']].head())\n",
    "\n",
    "#Next step: add 1 column for each of the top 10 and add the level for each user\n",
    "\n",
    "#status\n",
    "#print(data.status.unique())\n",
    "\n",
    "status_map = {\n",
    "    'single': 'single',\n",
    "    'available': 'single',\n",
    "    'seeing someone': 'committed',\n",
    "    'married': 'committed',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "\n",
    "data['status'] = data['status'].map(status_map)\n",
    "#print(data.status.unique())\n",
    "\n",
    "#numerical fields\n",
    "#print(data.describe())\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "data['height'].hist(bins=30)\n",
    "plt.xlabel('Height (inches)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data['age'].hist(bins=30)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "data = data[(data['age'] >= 18) & (data['age'] <= 90)] # reasonable interval for age\n",
    "data = data[(data['height'] >= 54) & (data['height'] <= 84)] # reasonable interval for height\n",
    "\n",
    "data = data.drop(columns=['income']) #around 80% of values are missing, will just drop the column\n",
    "\n",
    "# still need to drop: diet, education, last_online, offspring, pets, speaks -> other columns were created based on this information\n",
    "\n",
    "data = data.drop(columns=['diet', 'education', 'last_online', 'offspring', 'pets', 'speaks'])\n",
    "\n",
    "#now drop columns where unknowns are more than 50%\n",
    "\n",
    "cat_cols = data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "threshold = 0.5\n",
    "high_unknown_cols = []\n",
    "for col in cat_cols:\n",
    "    p = (data[col] == 'unknown').mean()\n",
    "    if p > threshold:\n",
    "        high_unknown_cols.append(col)\n",
    "\n",
    "#print(high_unknown_cols)\n",
    "\n",
    "\n",
    "# drop dominant columns\n",
    "def drop_dominant_columns(df, threshold=0.95):\n",
    "    drop_cols = []\n",
    "    for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "        top_freq = df[col].value_counts(normalize=True).iloc[0]\n",
    "        if top_freq > threshold:\n",
    "            drop_cols.append(col)\n",
    "    print('will drop ', drop_cols)\n",
    "    return df.drop(columns=drop_cols), drop_cols\n",
    "\n",
    "data, dropped = drop_dominant_columns(data, threshold=0.95)\n",
    "print(f\"Dropped columns due to dominance: {dropped}\")\n",
    "\n",
    "data = data.drop(columns=high_unknown_cols)\n",
    "\n",
    "not_essay_cols = [col for col in data.columns if 'essay' not in col]\n",
    "print(data[not_essay_cols].head())\n",
    "print(data[not_essay_cols].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Helper module with funtions\n",
    "\n",
    "def downsample(df, col):\n",
    "    min_count = df[col].value_counts().min()\n",
    "    balanced_df = pd.concat([\n",
    "        df[df[col] == category].sample(n=min_count, random_state=1)\n",
    "        for category in df[col].unique()\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample(df, target_col):\n",
    "    # Split into majority and minority classes\n",
    "    classes = df[target_col].value_counts().index\n",
    "    max_count = df[target_col].value_counts().max()\n",
    "\n",
    "    df_upsampled = []\n",
    "\n",
    "    for cls in classes:\n",
    "        df_class = df[df[target_col] == cls]\n",
    "        df_class_upsampled = resample(\n",
    "            df_class,\n",
    "            replace=True,               # Sample with replacement\n",
    "            n_samples=max_count,        # Match majority class\n",
    "            random_state=42\n",
    "        )\n",
    "        df_upsampled.append(df_class_upsampled)\n",
    "\n",
    "    return pd.concat(df_upsampled).sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type\n",
      "fit        0.416228\n",
      "average    0.244609\n",
      "plus       0.133604\n",
      "slim       0.108333\n",
      "unknown    0.097226\n",
      "Name: proportion, dtype: float64\n",
      "drinks\n",
      "moderate       0.697383\n",
      "light          0.099414\n",
      "heavy          0.093902\n",
      "non-drinker    0.054467\n",
      "unknown        0.049590\n",
      "very heavy     0.005245\n",
      "Name: proportion, dtype: float64\n",
      "drugs\n",
      "never        0.629503\n",
      "unknown      0.234838\n",
      "sometimes    0.128977\n",
      "often        0.006681\n",
      "Name: proportion, dtype: float64\n",
      "ethnicity\n",
      "white               0.558735\n",
      "asian               0.136828\n",
      "unknown             0.094603\n",
      "hispanic / latin    0.072990\n",
      "black               0.051244\n",
      "other               0.028328\n",
      "indian              0.019976\n",
      "middle eastern      0.013529\n",
      "pacific islander    0.011942\n",
      "native american     0.011825\n",
      "Name: proportion, dtype: float64\n",
      "job\n",
      "Other               0.270482\n",
      "STEM                0.159476\n",
      "Business            0.150741\n",
      "Creative            0.111607\n",
      "Student             0.081392\n",
      "Healthcare          0.061432\n",
      "Education           0.058609\n",
      "Service             0.053248\n",
      "Government / Law    0.038232\n",
      "Transportation      0.006113\n",
      "Unemployed          0.004526\n",
      "Retired             0.004142\n",
      "Name: proportion, dtype: float64\n",
      "orientation\n",
      "straight    0.860801\n",
      "gay         0.093033\n",
      "bisexual    0.046166\n",
      "Name: proportion, dtype: float64\n",
      "religion\n",
      "unknown         0.337409\n",
      "agnosticism     0.146999\n",
      "other           0.129061\n",
      "atheism         0.116551\n",
      "christianity    0.096558\n",
      "catholicism     0.079437\n",
      "judaism         0.051678\n",
      "buddhism        0.032503\n",
      "hinduism        0.007516\n",
      "islam           0.002288\n",
      "Name: proportion, dtype: float64\n",
      "sex\n",
      "m    0.597618\n",
      "f    0.402382\n",
      "Name: proportion, dtype: float64\n",
      "sign\n",
      "unknown        0.184330\n",
      "leo            0.072940\n",
      "gemini         0.071905\n",
      "libra          0.070201\n",
      "cancer         0.070184\n",
      "virgo          0.069132\n",
      "taurus         0.069032\n",
      "scorpio        0.068965\n",
      "aries          0.066593\n",
      "pisces         0.065808\n",
      "sagittarius    0.065775\n",
      "aquarius       0.065524\n",
      "capricorn      0.059611\n",
      "Name: proportion, dtype: float64\n",
      "smokes\n",
      "no           0.732508\n",
      "sometimes    0.113845\n",
      "unknown      0.091831\n",
      "yes          0.061816\n",
      "Name: proportion, dtype: float64\n",
      "diet_type\n",
      "anything      0.465334\n",
      "unknown       0.406775\n",
      "vegetarian    0.083229\n",
      "other         0.029731\n",
      "vegan         0.011725\n",
      "kosher        0.001921\n",
      "halal         0.001286\n",
      "Name: proportion, dtype: float64\n",
      "diet_strictness\n",
      "unknown     0.406775\n",
      "flexible    0.358872\n",
      "standard    0.122530\n",
      "strict      0.111824\n",
      "Name: proportion, dtype: float64\n",
      "education_status\n",
      "finished       0.679895\n",
      "in progress    0.174609\n",
      "unknown        0.110437\n",
      "dropped out    0.035059\n",
      "Name: proportion, dtype: float64\n",
      "education_level\n",
      "college        0.575537\n",
      "masters        0.182292\n",
      "unknown        0.138364\n",
      "phd            0.040136\n",
      "high school    0.028495\n",
      "law school     0.023801\n",
      "med school     0.011374\n",
      "Name: proportion, dtype: float64\n",
      "presence\n",
      "active         0.608692\n",
      "not active     0.326836\n",
      "semi-active    0.064472\n",
      "Name: proportion, dtype: float64\n",
      "sign_importance\n",
      "unknown          0.386681\n",
      "fun              0.322627\n",
      "not important    0.279518\n",
      "important        0.011174\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check class imbalance\n",
    "\n",
    "cols = data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cols = [col for col in cols if 'essay' not in col]\n",
    "\n",
    "for column in cols:\n",
    "    print(data[column].value_counts(normalize = True)) #check if the classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'income'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'income'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mbody_type\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mbody_type\u001b[39m\u001b[33m'\u001b[39m].map(map_body)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#remove rows where the target variable is unknown\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m df = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_to_predict\u001b[49m\u001b[43m]\u001b[49m != \u001b[33m'\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m#create vars with categorical columns and numerical columns\u001b[39;00m\n\u001b[32m     39\u001b[39m cat_cols = df.select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m]).columns.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'income'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = data[not_essay_cols].copy() #don't want to take into account essays for this\n",
    "\n",
    "col_to_predict = 'income'\n",
    "\n",
    "if col_to_predict == 'presence':\n",
    "    map_presence = {\n",
    "        'active': 'active',\n",
    "        'not active': 'not active',\n",
    "        'semi-active': 'not active'\n",
    "    }\n",
    "    df['presence'] = df['presence'].map(map_presence)\n",
    "\n",
    "if col_to_predict == 'body_type':\n",
    "    map_body = {\n",
    "        'fit': 'fit',\n",
    "        'average': 'not fit',\n",
    "        'plus': 'not fit',\n",
    "        'slim': 'not fit',\n",
    "        'unknown': 'unknown'    \n",
    "    }\n",
    "    df['body_type'] = df['body_type'].map(map_body)\n",
    "\n",
    "\n",
    "#remove rows where the target variable is unknown\n",
    "df = df[df[col_to_predict] != 'unknown']\n",
    "\n",
    "#create vars with categorical columns and numerical columns\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col != col_to_predict]\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "num_cols = [col for col in num_cols if col != col_to_predict]\n",
    "\n",
    "df_dummies = pd.get_dummies(df[cat_cols], drop_first = True)\n",
    "\n",
    "x = pd.concat([df[num_cols], df_dummies], axis = 1)\n",
    "y = df[col_to_predict]\n",
    "\n",
    "print(df[col_to_predict].value_counts(normalize = True)) #check if the classes are balanced\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "\n",
    "# ------------ Chi2 test ------------ #\n",
    "# Chi2 requires all values to be non-negative\n",
    "X_chi = x.copy()\n",
    "X_chi[X_chi < 0] = 0  # Only necessary if you have negative values\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=10)  # Keep top 10 features\n",
    "X_chi_selected = selector.fit_transform(X_chi, y)\n",
    "selected_features = X_chi.columns[selector.get_support()]\n",
    "print(f\"Selected features from Chi2: {list(selected_features)}\")\n",
    "\n",
    "x = x[selected_features]\n",
    "\n",
    "cat_cols = x.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = x.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# ------------ End of Chi2 test ------------ #\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=24, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[num_cols] = scaler.fit_transform(x_train[num_cols])\n",
    "x_test[num_cols] = scaler.transform(x_test[num_cols]) #never use fit transform on test data, because it will learn from train data\n",
    "\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "# ----- XGB Classifier ----- #\n",
    "counter = Counter(y_train)\n",
    "majority = max(counter.values())\n",
    "minority = min(counter.values())\n",
    "imbalance_ratio = majority / minority\n",
    "\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=imbalance_ratio\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_macro', verbose=1, n_jobs=-1)    \n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "y_pred = gs.predict(x_test)\n",
    "print('Classification report for XGB Classifier:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------- Logistic Regression ------------- #\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver = 'lbfgs', max_iter = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_model = model.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred_model)\n",
    "print('Classification report for LR:')\n",
    "print(model_score)\n",
    "\n",
    "## THROWS AN ERROR PREDICTING NUMERICAL COLUMNS: ---> 36 df = df[df[col_to_predict] != 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrf = RandomForestClassifier(class_weight='balanced')\\nrf.fit(x_train, y_train)\\ny_pred_rf = rf.predict(x_test)\\nrf_score = classification_report(y_test, y_pred_rf)\\nprint('Classification report for RF:')\\nprint(rf_score)\\n\\nimportances = pd.Series(rf.feature_importances_, index=x_train.columns)\\nprint(importances.sort_values(ascending=False).head(10))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stuff not used\n",
    "\n",
    "'''\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight='balanced')\n",
    "print('1')\n",
    "model.fit(x_train, y_train)\n",
    "print('2')\n",
    "y_pred = model.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred)\n",
    "print('Classification report SVC:')\n",
    "print(model_score)\n",
    "\n",
    "#DO FEATURE SELECTION\n",
    "#DO HYPERPARAMETER TUNING\n",
    "#DO CLASS MERGE (IF NEEDED)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "model = LogisticRegression(class_weight='balanced', solver = 'lbfgs', max_iter = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_model = model.predict(x_test)\n",
    "model_score = classification_report(y_test, y_pred_model)\n",
    "print('Classification report for LR:')\n",
    "print(model_score)\n",
    "'''\n",
    "\n",
    "'''\n",
    "smote = SMOTE(random_state=24)\n",
    "x_resampled, y_resampled = smote.fit_resample(x_train, y_train) #use SMOTE to make sure the classes are balanced\n",
    "'''\n",
    "\n",
    "'''\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "x = selector.fit_transform(x)\n",
    "'''\n",
    "\n",
    "# -------- Apply downsampling to make sure the classes are balanced --------------\n",
    "'''\n",
    "# Convert y_train back to Series with the correct index\n",
    "y_train_series = pd.Series(y_train, index=x_train.index, name=col_to_predict)\n",
    "\n",
    "# Concatenate features and target\n",
    "train_data = pd.concat([x_train, y_train_series], axis=1)\n",
    "\n",
    "train_balanced = downsample(train_data, col_to_predict)\n",
    "x_train = train_balanced.drop(columns = col_to_predict)\n",
    "y_train = train_balanced[col_to_predict]\n",
    "'''\n",
    "# -------- Downsampling ends here --------------\n",
    "\n",
    "# ----- Random forests ----- #\n",
    "'''\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "rf_score = classification_report(y_test, y_pred_rf)\n",
    "print('Classification report for RF:')\n",
    "print(rf_score)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=x_train.columns)\n",
    "print(importances.sort_values(ascending=False).head(10))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
